{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient: \n",
    "- A gradient is basically the slope of a function i.e, the degree of change of a parameter with the amount of change in another parameter. Mathematically, it can be described as the partial derivatives of a set of parameters with respect to its inputs.\n",
    "- The more the gradient, the steeper the slope.\n",
    "- Gradient is zero at a local maximum or minimum because there is no single direction of increase.\n",
    "- As gradient is a vector pointing at the greatest increase of a function, negative gradient is a vector pointing at the greatest decrease of a function.\n",
    "\n",
    "## Gradient Descent:\n",
    "- Gradient Descent is a optimization technique. Gradient Descent can be described as an iterative method which is used to find the values of the parameters of a function that minimizes the cost function as much as possible.\n",
    "- Gradient Descent is a convex function.\n",
    "- We can minimize loss function by iteratively moving a little bit in the direction of negative gradient.\n",
    "\n",
    "- Ex. In linear regression, gradient descent can fit a line to data by finding the optimal values for the intercept and slope. Here we partially differentiate the loss function(S.S.E or M.S.E) with respect to intercept and slope.\n",
    "\n",
    "**Step Size = Slope * Learning Rate**\n",
    "\n",
    "**New value = Old value  - Step Size**\n",
    "\n",
    "<img src = './Image/15.1 Image b.jpg' width='40%' height='40%'/>\n",
    "\n",
    "Gradient descent stops when the step size will be very close to zero, when slop is very close to zero.\n",
    "\n",
    "**NOTE: Convergence: If alpha is too small we may never converge and if it is too big we might overshoot. Below you can see that an alpha = 0.03 is too slow, alpha = 0.4 is just right and alpha = 1.02 is too big and gradient descent diverges.**\n",
    "<img src = './Image/15.1 Image a.gif'>\n",
    "\n",
    "### Types of Gradient Descent:\n",
    "Typically, there are three types of Gradient Descent:\n",
    "\n",
    "1) Batch Gradient Descent\n",
    "\n",
    "2) Stochastic Gradient Descent\n",
    "\n",
    "3) Mini-batch Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stochastic Gradient Descent:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
